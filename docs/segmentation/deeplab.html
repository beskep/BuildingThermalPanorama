<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pano.segmentation.deeplab API documentation</title>
<meta name="description" content="DeepLabV3+" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pano.segmentation.deeplab</code></h1>
</header>
<section id="section-intro">
<p>DeepLabV3+</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;DeepLabV3+&#34;&#34;&#34;

from pathlib import Path
from typing import List, Optional, Tuple, Union

from loguru import logger
from matplotlib import gridspec
from matplotlib import pyplot as plt
import numpy as np
import PIL.Image
from PIL.Image import Image as PILImage
from rich.progress import track
from skimage.transform import resize as _resize
import tensorflow.compat.v1 as tf


def tf_gpu_memory_config():
  config = tf.ConfigProto()
  config.gpu_options.allow_growth = True
  sess = tf.Session(config=config)

  return sess


def create_pascal_label_colormap() -&gt; np.ndarray:
  &#34;&#34;&#34;
  Creates a label colormap used in PASCAL VOC segmentation benchmark.

  Returns
  -------
  np.ndarray
      A Colormap for visualizing segmentation results.
  &#34;&#34;&#34;
  colormap = np.zeros((256, 3), dtype=int)
  ind = np.arange(256, dtype=int)

  for shift in reversed(range(8)):
    for channel in range(3):
      colormap[:, channel] |= ((ind &gt;&gt; channel) &amp; 1) &lt;&lt; shift
    ind &gt;&gt;= 3

  return colormap


def label_to_color_image(label: np.ndarray, cmap=&#39;pascal&#39;) -&gt; np.ndarray:
  &#34;&#34;&#34;
  Adds color defined by the dataset colormap to the label.

  Parameters
  ----------
  label : np.ndarray
      A 2D array with integer type, storing the segmentation label.
  cmap : str, optional
      Colormap. &#39;pascal&#39; or matplotlib&#39;s colormap name.

  Returns
  -------
  np.ndarray
      A 2D array with floating type. The element of the array is the color
      indexed by the corresponding element in the input label to the PASCAL
      color map.

  Raises
  ------
  ValueError
      If label is not of rank 2 or its value is larger than color
      map maximum entry.
  &#34;&#34;&#34;
  if label.ndim != 2:
    raise ValueError(&#39;Expect 2-D input label&#39;)

  if cmap == &#39;pascal&#39;:
    colormap = create_pascal_label_colormap()
  else:
    colormap = np.array(plt.get_cmap(cmap).colors) * 255

  if np.max(label) &gt;= len(colormap):
    raise ValueError(&#39;label value too large.&#39;)

  return colormap[label]


LABEL_NAMES = np.asarray([&#39;Background&#39;, &#39;Wall&#39;, &#39;Window&#39;, &#39;etc.&#39;])

FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)
# FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)


def vis_segmentation(image: Union[np.ndarray, PILImage],
                     seg_map: np.ndarray,
                     show=False,
                     cmap=&#39;pascal&#39;) -&gt; Tuple[plt.Figure, np.ndarray]:
  &#34;&#34;&#34;
  Visualizes input image, segmentation map and overlay view.

  Parameters
  ----------
  image : Union[np.ndarray, PILImage]
      Target image
  seg_map : np.ndarray
      Segmentation map.
  show : bool, optional
      Whether show matplotlib plot, by default False
  cmap : str, optional
      Colormap, by default &#39;pascal&#39;

  Returns
  -------
  fig : plt.Figure
      figure
  seg_image: np.ndarray
      Segmentation map with color
  &#34;&#34;&#34;
  fig = plt.figure(figsize=(15, 5))
  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[8, 8, 8, 1])

  plt.subplot(grid_spec[0])
  plt.imshow(image)
  plt.axis(&#39;off&#39;)
  plt.title(&#39;input image&#39;)

  plt.subplot(grid_spec[1])
  seg_image = label_to_color_image(seg_map, cmap=cmap).astype(np.uint8)
  plt.imshow(seg_image)
  plt.axis(&#39;off&#39;)
  plt.title(&#39;segmentation map&#39;)

  plt.subplot(grid_spec[2])
  plt.imshow(image)
  plt.imshow(seg_image, alpha=0.7)
  plt.axis(&#39;off&#39;)
  plt.title(&#39;segmentation overlay&#39;)

  full_color_map = label_to_color_image(FULL_LABEL_MAP, cmap=cmap)
  unique_labels = np.unique(seg_map)
  ax = plt.subplot(grid_spec[3])
  plt.imshow(full_color_map[unique_labels].astype(np.uint8),
             interpolation=&#39;nearest&#39;)
  ax.yaxis.tick_right()
  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])
  plt.xticks([], [])
  ax.tick_params(width=0.0)
  plt.grid(&#39;off&#39;)

  fig.tight_layout()

  if show:
    plt.show()

  return fig, seg_image


def predict(model_path: str,
            images: List[np.ndarray],
            outpug_dir: Path,
            cmap=&#39;Dark2&#39;,
            names: Optional[List[str]] = None):
  &#34;&#34;&#34;
  입력받은 각 영상을 DeepLabV3+ 모델을 통해 segment하고 결과를 저장.

  Parameters
  ----------
  model_path : str
      학습한 DeepLabV3+ 모델의 frozen graph 경로.
  images : List[np.ndarray]
      영상 목록
  outpug_dir : Path
      결과 저장 경로
  cmap : str, optional
      Colormap, by default &#39;Dark2&#39;
  names : Optional[List[str]], optional
      저장할 파일 이름 목록. 미지정 시 &#39;Image n&#39; 형식으로 저장.
  &#34;&#34;&#34;
  tf_gpu_memory_config()

  model = DeepLabModel(graph_path=model_path)

  if names is None:
    names = [f&#39;Image {x+1}&#39; for x in range(len(images))]

  for image, fname in track(zip(images, names)):
    pil_image = PIL.ImageImage.fromarray(image)

    resized_image, seg_map = model.run(pil_image)
    fig, seg_image = vis_segmentation(resized_image,
                                      seg_map,
                                      show=False,
                                      cmap=cmap)

    mask = PIL.ImageImage.fromarray(seg_map)
    mask.save(outpug_dir.joinpath(fname + &#39;_mask&#39;).with_suffix(&#39;.png&#39;))

    seg_image = PIL.ImageImage.fromarray(seg_image)
    seg_image.save(outpug_dir.joinpath(fname + &#39;_vis&#39;).with_suffix(&#39;.png&#39;))

    fig.savefig(outpug_dir.joinpath(fname + &#39;_fig&#39;).with_suffix(&#39;.png&#39;))
    plt.close(fig)


class DeepLabModel:
  &#34;&#34;&#34;
  학습된 DeepLabV3+ 모델의 실행 인터페이스를 제공하는 클래스.

  https://github.com/tensorflow/models/tree/master/research/deeplab 참조
  &#34;&#34;&#34;

  INPUT_TENSOR_NAME = &#39;ImageTensor:0&#39;
  OUTPUT_TENSOR_NAME = &#39;SemanticPredictions:0&#39;
  INPUT_SIZE = 641
  FROZEN_GRAPH_NAME = &#39;frozen_inference_graph&#39;

  def __init__(self, graph_path):
    &#34;&#34;&#34;Creates and loads pretrained deeplab model.&#34;&#34;&#34;
    self.graph = tf.Graph()

    try:
      graph_def = tf.GraphDef()
      with tf.io.gfile.GFile(graph_path, &#39;rb&#39;) as f:
        graph_def.ParseFromString(f.read())
    except (RuntimeError, ValueError, OSError) as e:
      logger.exception(&#39;loading failed&#39;)
      raise RuntimeError(&#39;failed to load graph&#39;) from e

    with self.graph.as_default():
      tf.import_graph_def(graph_def, name=&#39;&#39;)

    self.sess = tf.Session(graph=self.graph)

  def run(self, image: PILImage) -&gt; Tuple[PILImage, np.ndarray]:
    &#34;&#34;&#34;
    Runs inference on a single image.

    Parameters
    ----------
    image : PILImage
        A PIL.Image object, raw input image.

    Returns
    -------
    resized_image: PILImage
        RGB image resized from original input image.
    seg_map: np.ndarray
        Segmentation map of `resized_image`.
    &#34;&#34;&#34;
    width, height = image.size
    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)
    target_size = (int(resize_ratio * width), int(resize_ratio * height))
    resized_image = image.convert(&#39;RGB&#39;).resize(target_size,
                                                PIL.Image.ANTIALIAS)
    batch_seg_map = self.sess.run(
        self.OUTPUT_TENSOR_NAME,
        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})
    seg_map = batch_seg_map[0]

    return resized_image, seg_map

  def predict_and_visualize(
      self,
      image: np.ndarray,
      cmap=&#39;Dark2&#39;,
      resize=True) -&gt; Tuple[np.ndarray, np.ndarray, plt.Figure]:
    &#34;&#34;&#34;
    주어진 영상으로 segmentation 예측 및 시각화

    Parameters
    ----------
    image : np.ndarray
        대상 영상
    cmap : str, optional
        Colormap, by default &#39;Dark2&#39;
    resize : bool, optional
        `True`이면 원본 영상으로 resize한 결과 반환

    Returns
    -------
    segmentation_map : np.ndarray
        Segmentation 인덱스 맵.
        {0: &#39;Background&#39;, 1: &#39;Wall&#39;, 2: &#39;Window&#39;, 3: &#39;etc.&#39;}
    segmentation_image : np.ndarray
        지정한 colormap을 통해 시각화한 segmentation map
    fig : plt.Figure
        Raw image, segmentation map, overlay 영상을 담은 matplotlib figure
    &#34;&#34;&#34;
    pil_image = PIL.Image.fromarray(image)
    resized_image, seg_map = self.run(image=pil_image)

    resized_shape = (resized_image.height, resized_image.width)
    if not (resize or image.shape[:2] == resized_shape):
      vis_image = resized_image
    else:
      vis_image = image
      seg_map = _resize(seg_map,
                        output_shape=image.shape[:2],
                        preserve_range=True,
                        anti_aliasing=True)
      seg_map = np.round(seg_map).astype(np.uint8)

    fig, seg_image = vis_segmentation(image=vis_image,
                                      seg_map=seg_map,
                                      show=False,
                                      cmap=cmap)

    return seg_map, seg_image, fig</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pano.segmentation.deeplab.create_pascal_label_colormap"><code class="name flex">
<span>def <span class="ident">create_pascal_label_colormap</span></span>(<span>) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a label colormap used in PASCAL VOC segmentation benchmark.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>A Colormap for visualizing segmentation results.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_pascal_label_colormap() -&gt; np.ndarray:
  &#34;&#34;&#34;
  Creates a label colormap used in PASCAL VOC segmentation benchmark.

  Returns
  -------
  np.ndarray
      A Colormap for visualizing segmentation results.
  &#34;&#34;&#34;
  colormap = np.zeros((256, 3), dtype=int)
  ind = np.arange(256, dtype=int)

  for shift in reversed(range(8)):
    for channel in range(3):
      colormap[:, channel] |= ((ind &gt;&gt; channel) &amp; 1) &lt;&lt; shift
    ind &gt;&gt;= 3

  return colormap</code></pre>
</details>
</dd>
<dt id="pano.segmentation.deeplab.label_to_color_image"><code class="name flex">
<span>def <span class="ident">label_to_color_image</span></span>(<span>label: numpy.ndarray, cmap='pascal') ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Adds color defined by the dataset colormap to the label.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>label</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>A 2D array with integer type, storing the segmentation label.</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Colormap. 'pascal' or matplotlib's colormap name.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>A 2D array with floating type. The element of the array is the color
indexed by the corresponding element in the input label to the PASCAL
color map.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If label is not of rank 2 or its value is larger than color
map maximum entry.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def label_to_color_image(label: np.ndarray, cmap=&#39;pascal&#39;) -&gt; np.ndarray:
  &#34;&#34;&#34;
  Adds color defined by the dataset colormap to the label.

  Parameters
  ----------
  label : np.ndarray
      A 2D array with integer type, storing the segmentation label.
  cmap : str, optional
      Colormap. &#39;pascal&#39; or matplotlib&#39;s colormap name.

  Returns
  -------
  np.ndarray
      A 2D array with floating type. The element of the array is the color
      indexed by the corresponding element in the input label to the PASCAL
      color map.

  Raises
  ------
  ValueError
      If label is not of rank 2 or its value is larger than color
      map maximum entry.
  &#34;&#34;&#34;
  if label.ndim != 2:
    raise ValueError(&#39;Expect 2-D input label&#39;)

  if cmap == &#39;pascal&#39;:
    colormap = create_pascal_label_colormap()
  else:
    colormap = np.array(plt.get_cmap(cmap).colors) * 255

  if np.max(label) &gt;= len(colormap):
    raise ValueError(&#39;label value too large.&#39;)

  return colormap[label]</code></pre>
</details>
</dd>
<dt id="pano.segmentation.deeplab.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>model_path: str, images: List[numpy.ndarray], outpug_dir: pathlib.Path, cmap='Dark2', names: Optional[List[str]] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>입력받은 각 영상을 DeepLabV3+ 모델을 통해 segment하고 결과를 저장.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_path</code></strong> :&ensp;<code>str</code></dt>
<dd>학습한 DeepLabV3+ 모델의 frozen graph 경로.</dd>
<dt><strong><code>images</code></strong> :&ensp;<code>List[np.ndarray]</code></dt>
<dd>영상 목록</dd>
<dt><strong><code>outpug_dir</code></strong> :&ensp;<code>Path</code></dt>
<dd>결과 저장 경로</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Colormap, by default 'Dark2'</dd>
<dt><strong><code>names</code></strong> :&ensp;<code>Optional[List[str]]</code>, optional</dt>
<dd>저장할 파일 이름 목록. 미지정 시 'Image n' 형식으로 저장.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(model_path: str,
            images: List[np.ndarray],
            outpug_dir: Path,
            cmap=&#39;Dark2&#39;,
            names: Optional[List[str]] = None):
  &#34;&#34;&#34;
  입력받은 각 영상을 DeepLabV3+ 모델을 통해 segment하고 결과를 저장.

  Parameters
  ----------
  model_path : str
      학습한 DeepLabV3+ 모델의 frozen graph 경로.
  images : List[np.ndarray]
      영상 목록
  outpug_dir : Path
      결과 저장 경로
  cmap : str, optional
      Colormap, by default &#39;Dark2&#39;
  names : Optional[List[str]], optional
      저장할 파일 이름 목록. 미지정 시 &#39;Image n&#39; 형식으로 저장.
  &#34;&#34;&#34;
  tf_gpu_memory_config()

  model = DeepLabModel(graph_path=model_path)

  if names is None:
    names = [f&#39;Image {x+1}&#39; for x in range(len(images))]

  for image, fname in track(zip(images, names)):
    pil_image = PIL.ImageImage.fromarray(image)

    resized_image, seg_map = model.run(pil_image)
    fig, seg_image = vis_segmentation(resized_image,
                                      seg_map,
                                      show=False,
                                      cmap=cmap)

    mask = PIL.ImageImage.fromarray(seg_map)
    mask.save(outpug_dir.joinpath(fname + &#39;_mask&#39;).with_suffix(&#39;.png&#39;))

    seg_image = PIL.ImageImage.fromarray(seg_image)
    seg_image.save(outpug_dir.joinpath(fname + &#39;_vis&#39;).with_suffix(&#39;.png&#39;))

    fig.savefig(outpug_dir.joinpath(fname + &#39;_fig&#39;).with_suffix(&#39;.png&#39;))
    plt.close(fig)</code></pre>
</details>
</dd>
<dt id="pano.segmentation.deeplab.tf_gpu_memory_config"><code class="name flex">
<span>def <span class="ident">tf_gpu_memory_config</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tf_gpu_memory_config():
  config = tf.ConfigProto()
  config.gpu_options.allow_growth = True
  sess = tf.Session(config=config)

  return sess</code></pre>
</details>
</dd>
<dt id="pano.segmentation.deeplab.vis_segmentation"><code class="name flex">
<span>def <span class="ident">vis_segmentation</span></span>(<span>image: Union[numpy.ndarray, PIL.Image.Image], seg_map: numpy.ndarray, show=False, cmap='pascal') ‑> Tuple[matplotlib.figure.Figure, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Visualizes input image, segmentation map and overlay view.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>Union[np.ndarray, PILImage]</code></dt>
<dd>Target image</dd>
<dt><strong><code>seg_map</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Segmentation map.</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether show matplotlib plot, by default False</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Colormap, by default 'pascal'</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>plt.Figure</code></dt>
<dd>figure</dd>
<dt><strong><code>seg_image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Segmentation map with color</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vis_segmentation(image: Union[np.ndarray, PILImage],
                     seg_map: np.ndarray,
                     show=False,
                     cmap=&#39;pascal&#39;) -&gt; Tuple[plt.Figure, np.ndarray]:
  &#34;&#34;&#34;
  Visualizes input image, segmentation map and overlay view.

  Parameters
  ----------
  image : Union[np.ndarray, PILImage]
      Target image
  seg_map : np.ndarray
      Segmentation map.
  show : bool, optional
      Whether show matplotlib plot, by default False
  cmap : str, optional
      Colormap, by default &#39;pascal&#39;

  Returns
  -------
  fig : plt.Figure
      figure
  seg_image: np.ndarray
      Segmentation map with color
  &#34;&#34;&#34;
  fig = plt.figure(figsize=(15, 5))
  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[8, 8, 8, 1])

  plt.subplot(grid_spec[0])
  plt.imshow(image)
  plt.axis(&#39;off&#39;)
  plt.title(&#39;input image&#39;)

  plt.subplot(grid_spec[1])
  seg_image = label_to_color_image(seg_map, cmap=cmap).astype(np.uint8)
  plt.imshow(seg_image)
  plt.axis(&#39;off&#39;)
  plt.title(&#39;segmentation map&#39;)

  plt.subplot(grid_spec[2])
  plt.imshow(image)
  plt.imshow(seg_image, alpha=0.7)
  plt.axis(&#39;off&#39;)
  plt.title(&#39;segmentation overlay&#39;)

  full_color_map = label_to_color_image(FULL_LABEL_MAP, cmap=cmap)
  unique_labels = np.unique(seg_map)
  ax = plt.subplot(grid_spec[3])
  plt.imshow(full_color_map[unique_labels].astype(np.uint8),
             interpolation=&#39;nearest&#39;)
  ax.yaxis.tick_right()
  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])
  plt.xticks([], [])
  ax.tick_params(width=0.0)
  plt.grid(&#39;off&#39;)

  fig.tight_layout()

  if show:
    plt.show()

  return fig, seg_image</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pano.segmentation.deeplab.DeepLabModel"><code class="flex name class">
<span>class <span class="ident">DeepLabModel</span></span>
<span>(</span><span>graph_path)</span>
</code></dt>
<dd>
<div class="desc"><p>학습된 DeepLabV3+ 모델의 실행 인터페이스를 제공하는 클래스.</p>
<p><a href="https://github.com/tensorflow/models/tree/master/research/deeplab">https://github.com/tensorflow/models/tree/master/research/deeplab</a> 참조</p>
<p>Creates and loads pretrained deeplab model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DeepLabModel:
  &#34;&#34;&#34;
  학습된 DeepLabV3+ 모델의 실행 인터페이스를 제공하는 클래스.

  https://github.com/tensorflow/models/tree/master/research/deeplab 참조
  &#34;&#34;&#34;

  INPUT_TENSOR_NAME = &#39;ImageTensor:0&#39;
  OUTPUT_TENSOR_NAME = &#39;SemanticPredictions:0&#39;
  INPUT_SIZE = 641
  FROZEN_GRAPH_NAME = &#39;frozen_inference_graph&#39;

  def __init__(self, graph_path):
    &#34;&#34;&#34;Creates and loads pretrained deeplab model.&#34;&#34;&#34;
    self.graph = tf.Graph()

    try:
      graph_def = tf.GraphDef()
      with tf.io.gfile.GFile(graph_path, &#39;rb&#39;) as f:
        graph_def.ParseFromString(f.read())
    except (RuntimeError, ValueError, OSError) as e:
      logger.exception(&#39;loading failed&#39;)
      raise RuntimeError(&#39;failed to load graph&#39;) from e

    with self.graph.as_default():
      tf.import_graph_def(graph_def, name=&#39;&#39;)

    self.sess = tf.Session(graph=self.graph)

  def run(self, image: PILImage) -&gt; Tuple[PILImage, np.ndarray]:
    &#34;&#34;&#34;
    Runs inference on a single image.

    Parameters
    ----------
    image : PILImage
        A PIL.Image object, raw input image.

    Returns
    -------
    resized_image: PILImage
        RGB image resized from original input image.
    seg_map: np.ndarray
        Segmentation map of `resized_image`.
    &#34;&#34;&#34;
    width, height = image.size
    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)
    target_size = (int(resize_ratio * width), int(resize_ratio * height))
    resized_image = image.convert(&#39;RGB&#39;).resize(target_size,
                                                PIL.Image.ANTIALIAS)
    batch_seg_map = self.sess.run(
        self.OUTPUT_TENSOR_NAME,
        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})
    seg_map = batch_seg_map[0]

    return resized_image, seg_map

  def predict_and_visualize(
      self,
      image: np.ndarray,
      cmap=&#39;Dark2&#39;,
      resize=True) -&gt; Tuple[np.ndarray, np.ndarray, plt.Figure]:
    &#34;&#34;&#34;
    주어진 영상으로 segmentation 예측 및 시각화

    Parameters
    ----------
    image : np.ndarray
        대상 영상
    cmap : str, optional
        Colormap, by default &#39;Dark2&#39;
    resize : bool, optional
        `True`이면 원본 영상으로 resize한 결과 반환

    Returns
    -------
    segmentation_map : np.ndarray
        Segmentation 인덱스 맵.
        {0: &#39;Background&#39;, 1: &#39;Wall&#39;, 2: &#39;Window&#39;, 3: &#39;etc.&#39;}
    segmentation_image : np.ndarray
        지정한 colormap을 통해 시각화한 segmentation map
    fig : plt.Figure
        Raw image, segmentation map, overlay 영상을 담은 matplotlib figure
    &#34;&#34;&#34;
    pil_image = PIL.Image.fromarray(image)
    resized_image, seg_map = self.run(image=pil_image)

    resized_shape = (resized_image.height, resized_image.width)
    if not (resize or image.shape[:2] == resized_shape):
      vis_image = resized_image
    else:
      vis_image = image
      seg_map = _resize(seg_map,
                        output_shape=image.shape[:2],
                        preserve_range=True,
                        anti_aliasing=True)
      seg_map = np.round(seg_map).astype(np.uint8)

    fig, seg_image = vis_segmentation(image=vis_image,
                                      seg_map=seg_map,
                                      show=False,
                                      cmap=cmap)

    return seg_map, seg_image, fig</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="pano.segmentation.deeplab.DeepLabModel.FROZEN_GRAPH_NAME"><code class="name">var <span class="ident">FROZEN_GRAPH_NAME</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pano.segmentation.deeplab.DeepLabModel.INPUT_SIZE"><code class="name">var <span class="ident">INPUT_SIZE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pano.segmentation.deeplab.DeepLabModel.INPUT_TENSOR_NAME"><code class="name">var <span class="ident">INPUT_TENSOR_NAME</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pano.segmentation.deeplab.DeepLabModel.OUTPUT_TENSOR_NAME"><code class="name">var <span class="ident">OUTPUT_TENSOR_NAME</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pano.segmentation.deeplab.DeepLabModel.predict_and_visualize"><code class="name flex">
<span>def <span class="ident">predict_and_visualize</span></span>(<span>self, image: numpy.ndarray, cmap='Dark2', resize=True) ‑> Tuple[numpy.ndarray, numpy.ndarray, matplotlib.figure.Figure]</span>
</code></dt>
<dd>
<div class="desc"><p>주어진 영상으로 segmentation 예측 및 시각화</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>대상 영상</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Colormap, by default 'Dark2'</dd>
<dt><strong><code>resize</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd><code>True</code>이면 원본 영상으로 resize한 결과 반환</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>segmentation_map</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd 0: 1: 2: 3: _Background_="'Background'," _Wall_="'Wall'," _Window_="'Window'," _etc._="'etc.'">Segmentation 인덱스 맵.</dd>
<dt><strong><code>segmentation_image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>지정한 colormap을 통해 시각화한 segmentation map</dd>
<dt><strong><code>fig</code></strong> :&ensp;<code>plt.Figure</code></dt>
<dd>Raw image, segmentation map, overlay 영상을 담은 matplotlib figure</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_and_visualize(
    self,
    image: np.ndarray,
    cmap=&#39;Dark2&#39;,
    resize=True) -&gt; Tuple[np.ndarray, np.ndarray, plt.Figure]:
  &#34;&#34;&#34;
  주어진 영상으로 segmentation 예측 및 시각화

  Parameters
  ----------
  image : np.ndarray
      대상 영상
  cmap : str, optional
      Colormap, by default &#39;Dark2&#39;
  resize : bool, optional
      `True`이면 원본 영상으로 resize한 결과 반환

  Returns
  -------
  segmentation_map : np.ndarray
      Segmentation 인덱스 맵.
      {0: &#39;Background&#39;, 1: &#39;Wall&#39;, 2: &#39;Window&#39;, 3: &#39;etc.&#39;}
  segmentation_image : np.ndarray
      지정한 colormap을 통해 시각화한 segmentation map
  fig : plt.Figure
      Raw image, segmentation map, overlay 영상을 담은 matplotlib figure
  &#34;&#34;&#34;
  pil_image = PIL.Image.fromarray(image)
  resized_image, seg_map = self.run(image=pil_image)

  resized_shape = (resized_image.height, resized_image.width)
  if not (resize or image.shape[:2] == resized_shape):
    vis_image = resized_image
  else:
    vis_image = image
    seg_map = _resize(seg_map,
                      output_shape=image.shape[:2],
                      preserve_range=True,
                      anti_aliasing=True)
    seg_map = np.round(seg_map).astype(np.uint8)

  fig, seg_image = vis_segmentation(image=vis_image,
                                    seg_map=seg_map,
                                    show=False,
                                    cmap=cmap)

  return seg_map, seg_image, fig</code></pre>
</details>
</dd>
<dt id="pano.segmentation.deeplab.DeepLabModel.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, image: PIL.Image.Image) ‑> Tuple[PIL.Image.Image, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Runs inference on a single image.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>PILImage</code></dt>
<dd>A PIL.Image object, raw input image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>resized_image</code></strong> :&ensp;<code>PILImage</code></dt>
<dd>RGB image resized from original input image.</dd>
<dt><strong><code>seg_map</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Segmentation map of <code>resized_image</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self, image: PILImage) -&gt; Tuple[PILImage, np.ndarray]:
  &#34;&#34;&#34;
  Runs inference on a single image.

  Parameters
  ----------
  image : PILImage
      A PIL.Image object, raw input image.

  Returns
  -------
  resized_image: PILImage
      RGB image resized from original input image.
  seg_map: np.ndarray
      Segmentation map of `resized_image`.
  &#34;&#34;&#34;
  width, height = image.size
  resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)
  target_size = (int(resize_ratio * width), int(resize_ratio * height))
  resized_image = image.convert(&#39;RGB&#39;).resize(target_size,
                                              PIL.Image.ANTIALIAS)
  batch_seg_map = self.sess.run(
      self.OUTPUT_TENSOR_NAME,
      feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})
  seg_map = batch_seg_map[0]

  return resized_image, seg_map</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pano.segmentation" href="index.html">pano.segmentation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pano.segmentation.deeplab.create_pascal_label_colormap" href="#pano.segmentation.deeplab.create_pascal_label_colormap">create_pascal_label_colormap</a></code></li>
<li><code><a title="pano.segmentation.deeplab.label_to_color_image" href="#pano.segmentation.deeplab.label_to_color_image">label_to_color_image</a></code></li>
<li><code><a title="pano.segmentation.deeplab.predict" href="#pano.segmentation.deeplab.predict">predict</a></code></li>
<li><code><a title="pano.segmentation.deeplab.tf_gpu_memory_config" href="#pano.segmentation.deeplab.tf_gpu_memory_config">tf_gpu_memory_config</a></code></li>
<li><code><a title="pano.segmentation.deeplab.vis_segmentation" href="#pano.segmentation.deeplab.vis_segmentation">vis_segmentation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pano.segmentation.deeplab.DeepLabModel" href="#pano.segmentation.deeplab.DeepLabModel">DeepLabModel</a></code></h4>
<ul class="">
<li><code><a title="pano.segmentation.deeplab.DeepLabModel.FROZEN_GRAPH_NAME" href="#pano.segmentation.deeplab.DeepLabModel.FROZEN_GRAPH_NAME">FROZEN_GRAPH_NAME</a></code></li>
<li><code><a title="pano.segmentation.deeplab.DeepLabModel.INPUT_SIZE" href="#pano.segmentation.deeplab.DeepLabModel.INPUT_SIZE">INPUT_SIZE</a></code></li>
<li><code><a title="pano.segmentation.deeplab.DeepLabModel.INPUT_TENSOR_NAME" href="#pano.segmentation.deeplab.DeepLabModel.INPUT_TENSOR_NAME">INPUT_TENSOR_NAME</a></code></li>
<li><code><a title="pano.segmentation.deeplab.DeepLabModel.OUTPUT_TENSOR_NAME" href="#pano.segmentation.deeplab.DeepLabModel.OUTPUT_TENSOR_NAME">OUTPUT_TENSOR_NAME</a></code></li>
<li><code><a title="pano.segmentation.deeplab.DeepLabModel.predict_and_visualize" href="#pano.segmentation.deeplab.DeepLabModel.predict_and_visualize">predict_and_visualize</a></code></li>
<li><code><a title="pano.segmentation.deeplab.DeepLabModel.run" href="#pano.segmentation.deeplab.DeepLabModel.run">run</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>