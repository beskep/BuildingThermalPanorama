<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>src.distortion.perspective API documentation</title>
<meta name="description" content="시점 왜곡 보정" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.distortion.perspective</code></h1>
</header>
<section id="section-intro">
<p>시점 왜곡 보정</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;시점 왜곡 보정&#34;&#34;&#34;

import dataclasses as dc
from functools import cached_property
from typing import Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
from loguru import logger
from skimage.color import rgb2gray
from skimage.exposure.exposure import equalize_hist
from skimage.feature import canny
from skimage.transform import probabilistic_hough_line, warp

from misc.tools import erode, normalize_image

from . import rectification


class NotEnoughEdgelets(ValueError):
  pass


@dc.dataclass
class CannyOptions:
  &#34;&#34;&#34;`skimage.feature.canny` 옵션&#34;&#34;&#34;
  sigma: float = 1.0
  low_threshold: Optional[float] = None
  high_threshold: Optional[float] = None
  use_quantiles: bool = False


@dc.dataclass
class HoughOptions:
  &#34;&#34;&#34;`skimage.transform.probabilistic_hough_line` 옵션&#34;&#34;&#34;
  threshold: int = 10
  line_length: int = 50
  line_gap: int = 10
  theta: Optional[np.ndarray] = None
  seed: Optional[int] = None


@dc.dataclass
class CorrectionOptions:
  &#34;&#34;&#34;
  Parameters
  ----------
  threshold: float
      RANSAC VP 판단 알고리즘의 threshold [degree]
  ransac_iter: int
      RANSAC 반복 횟수
  clip_factor: float
  vp_iter: int
      (Vanishing point가 영상 내부에 존재하는 경우) 최대 반복 연산 횟수.
  &#34;&#34;&#34;
  threshold: float = 5.0
  ransac_iter: int = 1000
  clip_factor: float = 0.0
  vp_iter: int = 5
  erode: int = 50  # [pixel]

  strict: bool = False
  margin: float = 0.1


@dc.dataclass
class Edgelets:
  &#34;&#34;&#34;
  Parameters
  ----------
  locations : np.ndarray
      선분 중심 좌표. (count, 2).
  directions : np.ndarray
      선분 방향 벡터. Normalize 안함. (count, 2).
  strength : np.ndarray
      선분 길이. (count,).
  &#34;&#34;&#34;
  locations: np.ndarray
  directions: np.ndarray
  strengths: np.ndarray

  count: int = dc.field(init=False)

  def __post_init__(self):
    count = self.locations.shape[0]

    if self.locations.shape != (count, 2):
      raise ValueError(&#39;Invalid locations shape&#39;)
    if self.directions.shape != (count, 2):
      raise ValueError(&#39;Invalid directions shape&#39;)
    if self.strengths.shape != (count,):
      raise ValueError(&#39;Invalid strength shape&#39;)

    self.count = count

  def as_tuple(self):
    return (self.locations, self.directions, self.strengths)


class VanishingPoint:
  INSIDE = 0
  HORIZ = 1
  VERT = 2
  DIAG = 3

  SOFT = {HORIZ, VERT, DIAG}
  STRICT = {HORIZ, VERT}

  POS_DICT = {
      (True, True): DIAG,
      (True, False): HORIZ,
      (False, True): VERT,
      (False, False): INSIDE
  }

  def __init__(self, array: np.ndarray) -&gt; None:
    if array.shape != (3,):
      raise ValueError(&#39;Invalid vanishing point shape&#39;)

    self._array = array
    self._xy = np.divide(self.array[:2], self._array[2])
    self._pos: Optional[int] = None

  @property
  def array(self) -&gt; np.ndarray:
    return self._array

  @property
  def xy(self) -&gt; np.ndarray:
    return self._xy

  @property
  def pos(self) -&gt; int:
    if self._pos is None:
      raise ValueError(&#39;position not computed&#39;)

    return self._pos

  def compute_position(self, image_shape: tuple, margin=0.1):
    shape = np.array([image_shape[1], image_shape[0]])
    rxy = (self.xy - shape / 2.0) / shape
    hv = np.abs(rxy) &gt; 0.5 + margin

    self._pos = self.POS_DICT[(hv[0], hv[1])]


def compute_edgelets(
    image: np.ndarray,
    mask: Optional[np.ndarray] = None,
    canny_options: Optional[CannyOptions] = None,
    hough_options: Optional[HoughOptions] = None,
) -&gt; Tuple[Edgelets, np.ndarray]:
  &#34;&#34;&#34;
  영상의 edgelet 추출. `canny`을 통해 edge 추출 후,
  `probabilistic_hough_line`을 통해 계산한 선분의 중심 위치, 방향, 강도 (길이) 반환.

  Parameters
  ----------
  image : np.ndarray
      대상 영상. 2차원 흑백 영상이어야 함.
  mask : Optional[np.ndarray]
      edgelet을 인식할 영상 영역. dtype: bool
  canny_options : Optional[CannyOptions]
      `skimage.feature.canny` 옵션
  hough_options : Optional[HoughOptions]
      `skimage.transform.probabilistic_hough_line` 옵션

  Returns
  -------
  edgelets : Edgelets
  edges : np.ndarray
      `canny` 알고리즘을 통해 추출한 edge 영상

  Raises
  ------
  ValueError
      if image.ndim != 2
  &#34;&#34;&#34;
  if image.ndim != 2:
    raise ValueError(&#39;image.ndim != 2&#39;)
  if canny_options is None:
    canny_options = CannyOptions()
  if hough_options is None:
    hough_options = HoughOptions()

  edges = canny(image=normalize_image(image),
                mask=mask,
                **dc.asdict(canny_options))

  lines = probabilistic_hough_line(edges, **dc.asdict(hough_options))
  lines = np.array(lines)

  locations = np.average(lines, axis=1)
  directions = lines[:, 1, :] - lines[:, 0, :]
  strengths = np.linalg.norm(directions, ord=2, axis=1)
  directions = np.divide(directions, strengths.reshape([-1, 1]))

  edgelets = Edgelets(locations=locations,
                      directions=directions,
                      strengths=strengths)

  return edgelets, edges


def ransac_vanishing_point(edgelets: Edgelets,
                           num_ransac_iter=2000,
                           threshold_inlier=5):
  vp_array = rectification.ransac_vanishing_point(
      edgelets=edgelets.as_tuple(),
      num_ransac_iter=num_ransac_iter,
      threshold_inlier=threshold_inlier)
  vp = VanishingPoint(array=vp_array)

  return vp


def compute_votes(vp: VanishingPoint, edgelets: Edgelets, threshold_inlier=10):
  return rectification.compute_votes(edgelets=edgelets.as_tuple(),
                                     model=vp.array,
                                     threshold_inlier=threshold_inlier)


def remove_inliers(vp: VanishingPoint, edgelets: Edgelets, threshold_inlier=10):
  edgelets_tuple = rectification.remove_inliers(
      model=vp.array,
      edgelets=edgelets.as_tuple(),
      threshold_inlier=threshold_inlier)

  return Edgelets(*edgelets_tuple)


@dc.dataclass
class CorrectedImage:
  &#34;&#34;&#34;Perspective correction 결과&#34;&#34;&#34;
  image: Optional[np.ndarray] = None
  preprocessed: Optional[np.ndarray] = None

  edges: Optional[np.ndarray] = None
  edgelets: Optional[Edgelets] = None

  vp1: Optional[VanishingPoint] = None
  vp2: Optional[VanishingPoint] = None

  Hproject: Optional[np.ndarray] = None
  Haffine: Optional[np.ndarray] = None
  Htranslate: Optional[np.ndarray] = None

  output_shape: Optional[Tuple[int, int]] = None

  def success(self) -&gt; bool:
    return self.Htranslate is not None

  def correct(self, image: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;
    저장된 왜곡 보정 결과를 통해 새 영상 보정

    Parameters
    ----------
    image : np.ndarray
        보정 대상 영상.
        보정 계수를 추측한 영상과 크기 (width, height)가 동일해야 함.

    Returns
    -------
    np.ndarray
        Corrected image

    Raises
    ------
    ValueError
        if image.shape[:2] != self.image.shape[:2]
    &#34;&#34;&#34;
    assert self.image is not None
    if image.shape[:2] != self.image.shape[:2]:
      raise ValueError(&#39;입력한 영상의 해상도가 시점 왜곡을 추정한 영상의 해상도와 다릅니다.&#39;)

    return warp(image=image,
                inverse_map=np.linalg.inv(self.Htranslate),
                output_shape=self.output_shape,
                preserve_range=True)

  @cached_property
  def corrected_image(self) -&gt; np.ndarray:
    &#34;&#34;&#34;
    원본 영상 (`image` 변수)를 보정한 결과

    Returns
    -------
    np.ndarray
    &#34;&#34;&#34;
    return self.correct(self.image)

  def _visualize_model(self, ax: plt.Axes, vp: VanishingPoint):
    if self.edgelets is None:
      raise ValueError

    inliers = compute_votes(vp=vp, edgelets=self.edgelets,
                            threshold_inlier=10) &gt; 0

    locations = self.edgelets.locations[inliers]
    for idx in range(locations.shape[0]):
      ax.plot(
          [locations[idx, 0], vp.xy[0]],  # 소실점 선분 x 좌표
          [locations[idx, 1], vp.xy[1]],  # 소실점 선분 y 좌표
          &#39;b--&#39;)

  def process_plot(self) -&gt; Tuple[plt.Figure, plt.Axes]:
    &#34;&#34;&#34;보정 과정을 확인할 수 있는 matplotlib plot 생성&#34;&#34;&#34;
    if self.edgelets is None:
      raise ValueError

    fig, axes = plt.subplots(2, 3, figsize=(16, 9))

    # original image
    axes[0, 0].set_title(&#39;Original image&#39;)
    axes[0, 0].imshow(self.image)

    # preprocessed image
    axes[0, 1].set_title(&#39;Preprocess&#39;)
    axes[0, 1].imshow(self.preprocessed)

    # edges (canny and hough lines)
    axes[0, 2].set_title(&#39;Edges&#39;)
    axes[0, 2].imshow(self.edges)

    half_strengths = self.edgelets.strengths.reshape([-1, 1]) / 2.0
    pt1 = self.edgelets.locations - self.edgelets.directions * half_strengths
    pt2 = self.edgelets.locations + self.edgelets.directions * half_strengths
    for idx in range(self.edgelets.count):
      axes[0, 2].plot(
          [pt1[idx, 0], pt2[idx, 0]],
          [pt1[idx, 1], pt2[idx, 1]],
          &#39;r-&#39;,
      )

    # vanishing points
    axes[1, 0].set_title(&#39;Vanishing point 1&#39;)
    if self.vp1 is not None:
      axes[1, 0].imshow(self.edges)
      self._visualize_model(ax=axes[1, 0], vp=self.vp1)

    axes[1, 1].set_title(&#39;Vanishing point 2&#39;)
    if self.vp2 is not None:
      axes[1, 1].imshow(self.edges)
      self._visualize_model(ax=axes[1, 1], vp=self.vp2)

    # corrected image
    axes[1, 2].set_title(&#39;Corrected image&#39;)
    if self.success():
      axes[1, 2].imshow(self.corrected_image)

    for ax in axes.ravel():
      ax.set_axis_off()

    fig.tight_layout()

    return fig, axes


class PerspectiveCorrection:

  def __init__(self,
               canny_options: Optional[CannyOptions] = None,
               hough_options: Optional[HoughOptions] = None,
               correction_options: Optional[CorrectionOptions] = None) -&gt; None:
    &#34;&#34;&#34;
    영상의 소실점으로부터 시점 왜곡 (perspective distortion)을 보정하는
    Homography 행렬 추정.

    Parameters
    ----------
    canny_options : Optional[CannyOptions], optional
        `skimage.feature.canny` 옵션
    hough_options : Optional[HoughOptions], optional
        `skimage.transform.probabilistic_hough_line` 옵션
    correction_options : Optional[CorrectionOptions], optional
        소실점, 시점 보정 행렬의 수치적 추정을 위한 옵션
    &#34;&#34;&#34;
    if canny_options is None:
      canny_options = CannyOptions()
    if hough_options is None:
      hough_options = HoughOptions()
    if correction_options is None:
      correction_options = CorrectionOptions()

    self._canny_options = canny_options
    self._hough_options = hough_options
    self._opt = correction_options

  @staticmethod
  def preprocess(image: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;전처리 (회색 변환 및 히스토그램 평활화)&#34;&#34;&#34;
    if image.ndim == 3:
      gray = rgb2gray(image[:, :, :3])
    elif image.ndim == 2:
      gray = image
    else:
      raise ValueError(&#39;Dimension error&#39;)

    preprocessed = equalize_hist(image=gray)

    return preprocessed

  @staticmethod
  def _compute_affine(vp1: np.ndarray, vp2: np.ndarray,
                      H: np.ndarray) -&gt; np.ndarray:
    # Find directions corresponding to vanishing points
    v_post1 = np.dot(H, vp1)
    v_post2 = np.dot(H, vp2)
    v_post1 = v_post1 / np.sqrt(v_post1[0]**2 + v_post1[1]**2)
    v_post2 = v_post2 / np.sqrt(v_post2[0]**2 + v_post2[1]**2)

    directions = np.array([[v_post1[0], -v_post1[0], v_post2[0], -v_post2[0]],
                           [v_post1[1], -v_post1[1], v_post2[1], -v_post2[1]]])

    thetas = np.arctan2(directions[0], directions[1])

    # Find direction closest to horizontal axis
    h_ind = np.argmin(np.abs(thetas))

    # Find positive angle among the rest for the vertical axis
    if h_ind // 2 == 0:
      v_ind = 2 + np.argmax([thetas[2], thetas[3]])
    else:
      v_ind = np.argmax([thetas[2], thetas[3]])

    A1 = np.array([
        [directions[0, v_ind], directions[0, h_ind], 0],
        [directions[1, v_ind], directions[1, h_ind], 0],
        [0, 0, 1],
    ])

    # Might be a reflection. If so, remove reflection.
    if np.linalg.det(A1) &lt; 0:
      A1[:, 0] = -A1[:, 0]

    A = np.linalg.inv(A1)

    return A

  @staticmethod
  def _compute_translate(H: np.ndarray, shape: tuple, clip_factor: float):
    points = [
        [0, 0, shape[1], shape[1]],
        [0, shape[0], 0, shape[0]],
        [1, 1, 1, 1],
    ]
    cords = np.dot(H, points)
    cords = cords[:2] / cords[2]

    tx = min(0.0, cords[0].min())
    ty = min(0.0, cords[1].min())
    max_x = int(cords[0].max() - tx)
    max_y = int(cords[1].max() - ty)

    if clip_factor:
      max_offset = max(shape) * clip_factor / 2.0
      tx = max(tx, -max_offset)
      ty = max(ty, -max_offset)
      max_x = min(max_x, int(-tx + max_offset))
      max_y = min(max_y, int(-ty + max_offset))

    T = np.array([
        [1, 0, -tx],
        [0, 1, -ty],
        [0, 0, 1],
    ])

    return T, max_x, max_y

  def compute_homography(
      self,
      image: np.ndarray,
      vp1: np.ndarray,
      vp2: np.ndarray,
  ) -&gt; CorrectedImage:
    &#34;&#34;&#34;
    두 개의 소실점으로부터 시점 보정을 위한 homography 행렬 추정

    Parameters
    ----------
    image : np.ndarray
        대상 영상
    vp1 : np.ndarray
        소실점 1
    vp2 : np.ndarray
        소실점 2

    Returns
    -------
    CorrectedImage
        보정 결과. (원본/전처리 영상, `edges`, `edgelets` 결과 미포함)
    &#34;&#34;&#34;
    # Find Projective Transform
    vanishing_line = np.cross(vp1, vp2)
    Hproject = np.eye(3)
    Hproject[2] = vanishing_line / vanishing_line[2]
    Hproject = Hproject / Hproject[2, 2]

    # Computes affine transform to make axes corresponding to
    # vanishing points orthogonal
    A = self._compute_affine(vp1=vp1, vp2=vp2, H=Hproject)
    Haffine = np.dot(A, Hproject)

    # Image is translated so that the image is not missed.
    T, max_x, max_y = self._compute_translate(H=Haffine,
                                              shape=image.shape,
                                              clip_factor=self._opt.clip_factor)

    Htranslate = np.dot(T, Haffine)

    corrected = CorrectedImage(vp1=VanishingPoint(vp1),
                               vp2=VanishingPoint(vp2),
                               Hproject=Hproject,
                               Haffine=Haffine,
                               Htranslate=Htranslate,
                               output_shape=(max_y, max_x))

    return corrected

  def _estimate_vanishing_point(
      self,
      edgelets: Edgelets,
      image_shape: tuple,
      target: Optional[int] = None) -&gt; Tuple[VanishingPoint, Edgelets]:
    &#34;&#34;&#34;
    RANSAC을 통해 주어진 edgelet으로부터 vanishing point를 추정하고,
    vanishing point와 vanishing point에 수렴하는 inlier를 제외한 edgelets 반환.

    추정한 vanishing point가 대상 영상 내부에 존재하는 경우,
    해당 inlier를 제외하고 재연산.

    Parameters
    ----------
    edgelets : Edgelets
    image_shape : tuple
    target : Optional[int]
        추정 대상 VP의 위치 (VanishingPoint의 HORIZ, VERT)

    Returns
    -------
    VanishingPoint
        추정한 소실점
    Edgelets
        소실점에 수렴하는 edgelet을 제외한 edgelets

    Raises
    ------
    NotEnoughEdgelets
        조건에 맞지 않는 경우를 제외한 edgelet이 10개 미만인 경우
    ValueError
        Vanishing point 추정 실패
    &#34;&#34;&#34;
    vp = None
    for idx in range(self._opt.vp_iter + 1):
      logger.debug(&#39;Vanishing point iter {}&#39;, idx)
      if edgelets.count &lt; 10:
        raise NotEnoughEdgelets(&#39;Not enough edgelets&#39;)

      vp = ransac_vanishing_point(edgelets=edgelets,
                                  num_ransac_iter=self._opt.ransac_iter,
                                  threshold_inlier=self._opt.threshold)
      edgelets = remove_inliers(vp=vp,
                                edgelets=edgelets,
                                threshold_inlier=(2 * self._opt.threshold))

      vp.compute_position(image_shape=image_shape, margin=self._opt.margin)

      if target is None:
        if self._opt.strict:
          valid_positions = VanishingPoint.STRICT
        else:
          valid_positions = VanishingPoint.SOFT

        if vp.pos in valid_positions:
          break
      else:
        if vp.pos == target:
          break

    else:
      raise ValueError(&#39;Vanishing point 추정 실패&#39;)

    return vp, edgelets

  def _estimate_vanishing_points(
      self,
      edgelets: Edgelets,
      image_shape: Tuple[int, int],
  ) -&gt; Tuple[Optional[VanishingPoint], Optional[VanishingPoint]]:
    &#34;&#34;&#34;
    두 개의 vanishing point 추정

    Parameters
    ----------
    edgelets : Edgelets
        edgelets
    image_shape : Tuple[int, int]
        대상 영상 shape

    Returns
    -------
    Optional[VanishingPoint]
        Vanishing point 1
    Optional[VanishingPoint]
        Vanishing point 2
    &#34;&#34;&#34;
    vp1, vp2 = None, None
    vp1, edgelets2 = self._estimate_vanishing_point(edgelets=edgelets,
                                                    image_shape=image_shape)
    if vp1 is None:
      return None, None

    logger.debug(&#39;VP1: ({:.2f}, {:.2f})&#39;, *vp1.xy)

    target = None
    if self._opt.strict:
      target = (VanishingPoint.VERT
                if vp1.pos == VanishingPoint.HORIZ else VanishingPoint.HORIZ)
    vp2, _ = self._estimate_vanishing_point(edgelets=edgelets2,
                                            image_shape=image_shape,
                                            target=target)

    # 영상 중심으로부터 두 vp의 방향이 유사한지 확인
    if vp2 is not None:
      center = np.array([image_shape[1], image_shape[0]]) / 2.0
      vp1xy = vp1.xy - center
      vp2xy = vp2.xy - center

      delta = np.rad2deg(
          np.arctan2(vp1xy[1], vp1xy[0])  # vp1 angle
          - np.arctan2(vp2xy[1], vp2xy[0])  # vp2 angle
      )

      if np.abs(delta) &lt; 2 * self._opt.threshold:
        logger.warning(&#39;두 vanishing point가 유사함 (각도차: {:.2e} degree)&#39;, delta)
        vp2 = None

    if vp2 is not None:
      logger.debug(&#39;VP2: ({:.2f}, {:.2f})&#39;, *vp2.xy)

    return vp1, vp2

  def perspective_correct(self,
                          image: np.ndarray,
                          mask: Optional[np.ndarray] = None) -&gt; CorrectedImage:
    &#34;&#34;&#34;
    시점 왜곡 보정

    Parameters
    ----------
    image : np.ndarray
        대상 영상

    Returns
    -------
    CorrectedImage
    &#34;&#34;&#34;
    if self._opt.erode and mask is not None:
      logger.debug(&#39;Erode mask (iterations: {})&#39;, self._opt.erode)
      mask = erode(mask.astype(np.uint8),
                   iterations=self._opt.erode).astype(bool)

    preped = self.preprocess(image=image)

    edgelets, edges = compute_edgelets(image=preped,
                                       mask=mask,
                                       canny_options=self._canny_options,
                                       hough_options=self._hough_options)

    vp1, vp2 = self._estimate_vanishing_points(edgelets=edgelets,
                                               image_shape=image.shape[:2])

    if vp1 is not None and vp2 is not None:
      # homography 행렬 추정
      corrected = self.compute_homography(image=image,
                                          vp1=vp1.array,
                                          vp2=vp2.array)
      corrected.image = image
      corrected.preprocessed = preped
      corrected.edges = edges
      corrected.edgelets = edgelets
    else:
      # vp 추정 실패, 중간 과정만 저장
      corrected = CorrectedImage(image=image,
                                 preprocessed=preped,
                                 edges=edges,
                                 edgelets=edgelets,
                                 vp1=vp1,
                                 vp2=vp2)

    return corrected</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.distortion.perspective.compute_edgelets"><code class="name flex">
<span>def <span class="ident">compute_edgelets</span></span>(<span>image: numpy.ndarray, mask: Union[numpy.ndarray, NoneType] = None, canny_options: Union[<a title="src.distortion.perspective.CannyOptions" href="#src.distortion.perspective.CannyOptions">CannyOptions</a>, NoneType] = None, hough_options: Union[<a title="src.distortion.perspective.HoughOptions" href="#src.distortion.perspective.HoughOptions">HoughOptions</a>, NoneType] = None) ‑> Tuple[<a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a>, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>영상의 edgelet 추출. <code>canny</code>을 통해 edge 추출 후,
<code>probabilistic_hough_line</code>을 통해 계산한 선분의 중심 위치, 방향, 강도 (길이) 반환.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>대상 영상. 2차원 흑백 영상이어야 함.</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>Optional[np.ndarray]</code></dt>
<dd>edgelet을 인식할 영상 영역. dtype: bool</dd>
<dt><strong><code>canny_options</code></strong> :&ensp;<code>Optional[<a title="src.distortion.perspective.CannyOptions" href="#src.distortion.perspective.CannyOptions">CannyOptions</a>]</code></dt>
<dd><code>skimage.feature.canny</code> 옵션</dd>
<dt><strong><code>hough_options</code></strong> :&ensp;<code>Optional[<a title="src.distortion.perspective.HoughOptions" href="#src.distortion.perspective.HoughOptions">HoughOptions</a>]</code></dt>
<dd><code>skimage.transform.probabilistic_hough_line</code> 옵션</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>edgelets</code></strong> :&ensp;<code><a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a></code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>edges</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd><code>canny</code> 알고리즘을 통해 추출한 edge 영상</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>if image.ndim != 2</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_edgelets(
    image: np.ndarray,
    mask: Optional[np.ndarray] = None,
    canny_options: Optional[CannyOptions] = None,
    hough_options: Optional[HoughOptions] = None,
) -&gt; Tuple[Edgelets, np.ndarray]:
  &#34;&#34;&#34;
  영상의 edgelet 추출. `canny`을 통해 edge 추출 후,
  `probabilistic_hough_line`을 통해 계산한 선분의 중심 위치, 방향, 강도 (길이) 반환.

  Parameters
  ----------
  image : np.ndarray
      대상 영상. 2차원 흑백 영상이어야 함.
  mask : Optional[np.ndarray]
      edgelet을 인식할 영상 영역. dtype: bool
  canny_options : Optional[CannyOptions]
      `skimage.feature.canny` 옵션
  hough_options : Optional[HoughOptions]
      `skimage.transform.probabilistic_hough_line` 옵션

  Returns
  -------
  edgelets : Edgelets
  edges : np.ndarray
      `canny` 알고리즘을 통해 추출한 edge 영상

  Raises
  ------
  ValueError
      if image.ndim != 2
  &#34;&#34;&#34;
  if image.ndim != 2:
    raise ValueError(&#39;image.ndim != 2&#39;)
  if canny_options is None:
    canny_options = CannyOptions()
  if hough_options is None:
    hough_options = HoughOptions()

  edges = canny(image=normalize_image(image),
                mask=mask,
                **dc.asdict(canny_options))

  lines = probabilistic_hough_line(edges, **dc.asdict(hough_options))
  lines = np.array(lines)

  locations = np.average(lines, axis=1)
  directions = lines[:, 1, :] - lines[:, 0, :]
  strengths = np.linalg.norm(directions, ord=2, axis=1)
  directions = np.divide(directions, strengths.reshape([-1, 1]))

  edgelets = Edgelets(locations=locations,
                      directions=directions,
                      strengths=strengths)

  return edgelets, edges</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.compute_votes"><code class="name flex">
<span>def <span class="ident">compute_votes</span></span>(<span>vp: <a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a>, edgelets: <a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a>, threshold_inlier=10)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_votes(vp: VanishingPoint, edgelets: Edgelets, threshold_inlier=10):
  return rectification.compute_votes(edgelets=edgelets.as_tuple(),
                                     model=vp.array,
                                     threshold_inlier=threshold_inlier)</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.ransac_vanishing_point"><code class="name flex">
<span>def <span class="ident">ransac_vanishing_point</span></span>(<span>edgelets: <a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a>, num_ransac_iter=2000, threshold_inlier=5)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ransac_vanishing_point(edgelets: Edgelets,
                           num_ransac_iter=2000,
                           threshold_inlier=5):
  vp_array = rectification.ransac_vanishing_point(
      edgelets=edgelets.as_tuple(),
      num_ransac_iter=num_ransac_iter,
      threshold_inlier=threshold_inlier)
  vp = VanishingPoint(array=vp_array)

  return vp</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.remove_inliers"><code class="name flex">
<span>def <span class="ident">remove_inliers</span></span>(<span>vp: <a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a>, edgelets: <a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a>, threshold_inlier=10)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_inliers(vp: VanishingPoint, edgelets: Edgelets, threshold_inlier=10):
  edgelets_tuple = rectification.remove_inliers(
      model=vp.array,
      edgelets=edgelets.as_tuple(),
      threshold_inlier=threshold_inlier)

  return Edgelets(*edgelets_tuple)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.distortion.perspective.CannyOptions"><code class="flex name class">
<span>class <span class="ident">CannyOptions</span></span>
<span>(</span><span>sigma: float = 1.0, low_threshold: Union[float, NoneType] = None, high_threshold: Union[float, NoneType] = None, use_quantiles: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p><code>skimage.feature.canny</code> 옵션</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CannyOptions:
  &#34;&#34;&#34;`skimage.feature.canny` 옵션&#34;&#34;&#34;
  sigma: float = 1.0
  low_threshold: Optional[float] = None
  high_threshold: Optional[float] = None
  use_quantiles: bool = False</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.distortion.perspective.CannyOptions.high_threshold"><code class="name">var <span class="ident">high_threshold</span> : Union[float, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CannyOptions.low_threshold"><code class="name">var <span class="ident">low_threshold</span> : Union[float, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CannyOptions.sigma"><code class="name">var <span class="ident">sigma</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CannyOptions.use_quantiles"><code class="name">var <span class="ident">use_quantiles</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="src.distortion.perspective.CorrectedImage"><code class="flex name class">
<span>class <span class="ident">CorrectedImage</span></span>
<span>(</span><span>image: Union[numpy.ndarray, NoneType] = None, preprocessed: Union[numpy.ndarray, NoneType] = None, edges: Union[numpy.ndarray, NoneType] = None, edgelets: Union[<a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a>, NoneType] = None, vp1: Union[<a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a>, NoneType] = None, vp2: Union[<a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a>, NoneType] = None, Hproject: Union[numpy.ndarray, NoneType] = None, Haffine: Union[numpy.ndarray, NoneType] = None, Htranslate: Union[numpy.ndarray, NoneType] = None, output_shape: Union[Tuple[int, int], NoneType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perspective correction 결과</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CorrectedImage:
  &#34;&#34;&#34;Perspective correction 결과&#34;&#34;&#34;
  image: Optional[np.ndarray] = None
  preprocessed: Optional[np.ndarray] = None

  edges: Optional[np.ndarray] = None
  edgelets: Optional[Edgelets] = None

  vp1: Optional[VanishingPoint] = None
  vp2: Optional[VanishingPoint] = None

  Hproject: Optional[np.ndarray] = None
  Haffine: Optional[np.ndarray] = None
  Htranslate: Optional[np.ndarray] = None

  output_shape: Optional[Tuple[int, int]] = None

  def success(self) -&gt; bool:
    return self.Htranslate is not None

  def correct(self, image: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;
    저장된 왜곡 보정 결과를 통해 새 영상 보정

    Parameters
    ----------
    image : np.ndarray
        보정 대상 영상.
        보정 계수를 추측한 영상과 크기 (width, height)가 동일해야 함.

    Returns
    -------
    np.ndarray
        Corrected image

    Raises
    ------
    ValueError
        if image.shape[:2] != self.image.shape[:2]
    &#34;&#34;&#34;
    assert self.image is not None
    if image.shape[:2] != self.image.shape[:2]:
      raise ValueError(&#39;입력한 영상의 해상도가 시점 왜곡을 추정한 영상의 해상도와 다릅니다.&#39;)

    return warp(image=image,
                inverse_map=np.linalg.inv(self.Htranslate),
                output_shape=self.output_shape,
                preserve_range=True)

  @cached_property
  def corrected_image(self) -&gt; np.ndarray:
    &#34;&#34;&#34;
    원본 영상 (`image` 변수)를 보정한 결과

    Returns
    -------
    np.ndarray
    &#34;&#34;&#34;
    return self.correct(self.image)

  def _visualize_model(self, ax: plt.Axes, vp: VanishingPoint):
    if self.edgelets is None:
      raise ValueError

    inliers = compute_votes(vp=vp, edgelets=self.edgelets,
                            threshold_inlier=10) &gt; 0

    locations = self.edgelets.locations[inliers]
    for idx in range(locations.shape[0]):
      ax.plot(
          [locations[idx, 0], vp.xy[0]],  # 소실점 선분 x 좌표
          [locations[idx, 1], vp.xy[1]],  # 소실점 선분 y 좌표
          &#39;b--&#39;)

  def process_plot(self) -&gt; Tuple[plt.Figure, plt.Axes]:
    &#34;&#34;&#34;보정 과정을 확인할 수 있는 matplotlib plot 생성&#34;&#34;&#34;
    if self.edgelets is None:
      raise ValueError

    fig, axes = plt.subplots(2, 3, figsize=(16, 9))

    # original image
    axes[0, 0].set_title(&#39;Original image&#39;)
    axes[0, 0].imshow(self.image)

    # preprocessed image
    axes[0, 1].set_title(&#39;Preprocess&#39;)
    axes[0, 1].imshow(self.preprocessed)

    # edges (canny and hough lines)
    axes[0, 2].set_title(&#39;Edges&#39;)
    axes[0, 2].imshow(self.edges)

    half_strengths = self.edgelets.strengths.reshape([-1, 1]) / 2.0
    pt1 = self.edgelets.locations - self.edgelets.directions * half_strengths
    pt2 = self.edgelets.locations + self.edgelets.directions * half_strengths
    for idx in range(self.edgelets.count):
      axes[0, 2].plot(
          [pt1[idx, 0], pt2[idx, 0]],
          [pt1[idx, 1], pt2[idx, 1]],
          &#39;r-&#39;,
      )

    # vanishing points
    axes[1, 0].set_title(&#39;Vanishing point 1&#39;)
    if self.vp1 is not None:
      axes[1, 0].imshow(self.edges)
      self._visualize_model(ax=axes[1, 0], vp=self.vp1)

    axes[1, 1].set_title(&#39;Vanishing point 2&#39;)
    if self.vp2 is not None:
      axes[1, 1].imshow(self.edges)
      self._visualize_model(ax=axes[1, 1], vp=self.vp2)

    # corrected image
    axes[1, 2].set_title(&#39;Corrected image&#39;)
    if self.success():
      axes[1, 2].imshow(self.corrected_image)

    for ax in axes.ravel():
      ax.set_axis_off()

    fig.tight_layout()

    return fig, axes</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.distortion.perspective.CorrectedImage.Haffine"><code class="name">var <span class="ident">Haffine</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.Hproject"><code class="name">var <span class="ident">Hproject</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.Htranslate"><code class="name">var <span class="ident">Htranslate</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.edgelets"><code class="name">var <span class="ident">edgelets</span> : Union[<a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a>, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.edges"><code class="name">var <span class="ident">edges</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.image"><code class="name">var <span class="ident">image</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.output_shape"><code class="name">var <span class="ident">output_shape</span> : Union[Tuple[int, int], NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.preprocessed"><code class="name">var <span class="ident">preprocessed</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.vp1"><code class="name">var <span class="ident">vp1</span> : Union[<a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a>, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.vp2"><code class="name">var <span class="ident">vp2</span> : Union[<a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a>, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="src.distortion.perspective.CorrectedImage.corrected_image"><code class="name">var <span class="ident">corrected_image</span></code></dt>
<dd>
<div class="desc"><p>원본 영상 (<code>image</code> 변수)를 보정한 결과</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def __get__(self, instance, owner=None):
    if instance is None:
        return self
    if self.attrname is None:
        raise TypeError(
            &#34;Cannot use cached_property instance without calling __set_name__ on it.&#34;)
    try:
        cache = instance.__dict__
    except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)
        msg = (
            f&#34;No &#39;__dict__&#39; attribute on {type(instance).__name__!r} &#34;
            f&#34;instance to cache {self.attrname!r} property.&#34;
        )
        raise TypeError(msg) from None
    val = cache.get(self.attrname, _NOT_FOUND)
    if val is _NOT_FOUND:
        with self.lock:
            # check if another thread filled cache while we awaited lock
            val = cache.get(self.attrname, _NOT_FOUND)
            if val is _NOT_FOUND:
                val = self.func(instance)
                try:
                    cache[self.attrname] = val
                except TypeError:
                    msg = (
                        f&#34;The &#39;__dict__&#39; attribute on {type(instance).__name__!r} instance &#34;
                        f&#34;does not support item assignment for caching {self.attrname!r} property.&#34;
                    )
                    raise TypeError(msg) from None
    return val</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.distortion.perspective.CorrectedImage.correct"><code class="name flex">
<span>def <span class="ident">correct</span></span>(<span>self, image: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>저장된 왜곡 보정 결과를 통해 새 영상 보정</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>보정 대상 영상.
보정 계수를 추측한 영상과 크기 (width, height)가 동일해야 함.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Corrected image</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>if image.shape[:2] != self.image.shape[:2]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correct(self, image: np.ndarray) -&gt; np.ndarray:
  &#34;&#34;&#34;
  저장된 왜곡 보정 결과를 통해 새 영상 보정

  Parameters
  ----------
  image : np.ndarray
      보정 대상 영상.
      보정 계수를 추측한 영상과 크기 (width, height)가 동일해야 함.

  Returns
  -------
  np.ndarray
      Corrected image

  Raises
  ------
  ValueError
      if image.shape[:2] != self.image.shape[:2]
  &#34;&#34;&#34;
  assert self.image is not None
  if image.shape[:2] != self.image.shape[:2]:
    raise ValueError(&#39;입력한 영상의 해상도가 시점 왜곡을 추정한 영상의 해상도와 다릅니다.&#39;)

  return warp(image=image,
              inverse_map=np.linalg.inv(self.Htranslate),
              output_shape=self.output_shape,
              preserve_range=True)</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.process_plot"><code class="name flex">
<span>def <span class="ident">process_plot</span></span>(<span>self) ‑> Tuple[matplotlib.figure.Figure, matplotlib.axes._axes.Axes]</span>
</code></dt>
<dd>
<div class="desc"><p>보정 과정을 확인할 수 있는 matplotlib plot 생성</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_plot(self) -&gt; Tuple[plt.Figure, plt.Axes]:
  &#34;&#34;&#34;보정 과정을 확인할 수 있는 matplotlib plot 생성&#34;&#34;&#34;
  if self.edgelets is None:
    raise ValueError

  fig, axes = plt.subplots(2, 3, figsize=(16, 9))

  # original image
  axes[0, 0].set_title(&#39;Original image&#39;)
  axes[0, 0].imshow(self.image)

  # preprocessed image
  axes[0, 1].set_title(&#39;Preprocess&#39;)
  axes[0, 1].imshow(self.preprocessed)

  # edges (canny and hough lines)
  axes[0, 2].set_title(&#39;Edges&#39;)
  axes[0, 2].imshow(self.edges)

  half_strengths = self.edgelets.strengths.reshape([-1, 1]) / 2.0
  pt1 = self.edgelets.locations - self.edgelets.directions * half_strengths
  pt2 = self.edgelets.locations + self.edgelets.directions * half_strengths
  for idx in range(self.edgelets.count):
    axes[0, 2].plot(
        [pt1[idx, 0], pt2[idx, 0]],
        [pt1[idx, 1], pt2[idx, 1]],
        &#39;r-&#39;,
    )

  # vanishing points
  axes[1, 0].set_title(&#39;Vanishing point 1&#39;)
  if self.vp1 is not None:
    axes[1, 0].imshow(self.edges)
    self._visualize_model(ax=axes[1, 0], vp=self.vp1)

  axes[1, 1].set_title(&#39;Vanishing point 2&#39;)
  if self.vp2 is not None:
    axes[1, 1].imshow(self.edges)
    self._visualize_model(ax=axes[1, 1], vp=self.vp2)

  # corrected image
  axes[1, 2].set_title(&#39;Corrected image&#39;)
  if self.success():
    axes[1, 2].imshow(self.corrected_image)

  for ax in axes.ravel():
    ax.set_axis_off()

  fig.tight_layout()

  return fig, axes</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.CorrectedImage.success"><code class="name flex">
<span>def <span class="ident">success</span></span>(<span>self) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def success(self) -&gt; bool:
  return self.Htranslate is not None</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions"><code class="flex name class">
<span>class <span class="ident">CorrectionOptions</span></span>
<span>(</span><span>threshold: float = 5.0, ransac_iter: int = 1000, clip_factor: float = 0.0, vp_iter: int = 5, erode: int = 50, strict: bool = False, margin: float = 0.1)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>RANSAC VP 판단 알고리즘의 threshold [degree]</dd>
<dt><strong><code>ransac_iter</code></strong> :&ensp;<code>int</code></dt>
<dd>RANSAC 반복 횟수</dd>
<dt><strong><code>clip_factor</code></strong> :&ensp;<code>float</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>vp_iter</code></strong> :&ensp;<code>int</code></dt>
<dd>(Vanishing point가 영상 내부에 존재하는 경우) 최대 반복 연산 횟수.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CorrectionOptions:
  &#34;&#34;&#34;
  Parameters
  ----------
  threshold: float
      RANSAC VP 판단 알고리즘의 threshold [degree]
  ransac_iter: int
      RANSAC 반복 횟수
  clip_factor: float
  vp_iter: int
      (Vanishing point가 영상 내부에 존재하는 경우) 최대 반복 연산 횟수.
  &#34;&#34;&#34;
  threshold: float = 5.0
  ransac_iter: int = 1000
  clip_factor: float = 0.0
  vp_iter: int = 5
  erode: int = 50  # [pixel]

  strict: bool = False
  margin: float = 0.1</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.distortion.perspective.CorrectionOptions.clip_factor"><code class="name">var <span class="ident">clip_factor</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions.erode"><code class="name">var <span class="ident">erode</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions.margin"><code class="name">var <span class="ident">margin</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions.ransac_iter"><code class="name">var <span class="ident">ransac_iter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions.strict"><code class="name">var <span class="ident">strict</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions.threshold"><code class="name">var <span class="ident">threshold</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.CorrectionOptions.vp_iter"><code class="name">var <span class="ident">vp_iter</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="src.distortion.perspective.Edgelets"><code class="flex name class">
<span>class <span class="ident">Edgelets</span></span>
<span>(</span><span>locations: numpy.ndarray, directions: numpy.ndarray, strengths: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>locations</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>선분 중심 좌표. (count, 2).</dd>
<dt><strong><code>directions</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>선분 방향 벡터. Normalize 안함. (count, 2).</dd>
<dt><strong><code>strength</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>선분 길이. (count,).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Edgelets:
  &#34;&#34;&#34;
  Parameters
  ----------
  locations : np.ndarray
      선분 중심 좌표. (count, 2).
  directions : np.ndarray
      선분 방향 벡터. Normalize 안함. (count, 2).
  strength : np.ndarray
      선분 길이. (count,).
  &#34;&#34;&#34;
  locations: np.ndarray
  directions: np.ndarray
  strengths: np.ndarray

  count: int = dc.field(init=False)

  def __post_init__(self):
    count = self.locations.shape[0]

    if self.locations.shape != (count, 2):
      raise ValueError(&#39;Invalid locations shape&#39;)
    if self.directions.shape != (count, 2):
      raise ValueError(&#39;Invalid directions shape&#39;)
    if self.strengths.shape != (count,):
      raise ValueError(&#39;Invalid strength shape&#39;)

    self.count = count

  def as_tuple(self):
    return (self.locations, self.directions, self.strengths)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.distortion.perspective.Edgelets.count"><code class="name">var <span class="ident">count</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.Edgelets.directions"><code class="name">var <span class="ident">directions</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.Edgelets.locations"><code class="name">var <span class="ident">locations</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.Edgelets.strengths"><code class="name">var <span class="ident">strengths</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.distortion.perspective.Edgelets.as_tuple"><code class="name flex">
<span>def <span class="ident">as_tuple</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_tuple(self):
  return (self.locations, self.directions, self.strengths)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.distortion.perspective.HoughOptions"><code class="flex name class">
<span>class <span class="ident">HoughOptions</span></span>
<span>(</span><span>threshold: int = 10, line_length: int = 50, line_gap: int = 10, theta: Union[numpy.ndarray, NoneType] = None, seed: Union[int, NoneType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p><code>skimage.transform.probabilistic_hough_line</code> 옵션</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HoughOptions:
  &#34;&#34;&#34;`skimage.transform.probabilistic_hough_line` 옵션&#34;&#34;&#34;
  threshold: int = 10
  line_length: int = 50
  line_gap: int = 10
  theta: Optional[np.ndarray] = None
  seed: Optional[int] = None</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.distortion.perspective.HoughOptions.line_gap"><code class="name">var <span class="ident">line_gap</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.HoughOptions.line_length"><code class="name">var <span class="ident">line_length</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.HoughOptions.seed"><code class="name">var <span class="ident">seed</span> : Union[int, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.HoughOptions.theta"><code class="name">var <span class="ident">theta</span> : Union[numpy.ndarray, NoneType]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.HoughOptions.threshold"><code class="name">var <span class="ident">threshold</span> : int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="src.distortion.perspective.NotEnoughEdgelets"><code class="flex name class">
<span>class <span class="ident">NotEnoughEdgelets</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Inappropriate argument value (of correct type).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NotEnoughEdgelets(ValueError):
  pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.ValueError</li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="src.distortion.perspective.PerspectiveCorrection"><code class="flex name class">
<span>class <span class="ident">PerspectiveCorrection</span></span>
<span>(</span><span>canny_options: Union[<a title="src.distortion.perspective.CannyOptions" href="#src.distortion.perspective.CannyOptions">CannyOptions</a>, NoneType] = None, hough_options: Union[<a title="src.distortion.perspective.HoughOptions" href="#src.distortion.perspective.HoughOptions">HoughOptions</a>, NoneType] = None, correction_options: Union[<a title="src.distortion.perspective.CorrectionOptions" href="#src.distortion.perspective.CorrectionOptions">CorrectionOptions</a>, NoneType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>영상의 소실점으로부터 시점 왜곡 (perspective distortion)을 보정하는
Homography 행렬 추정.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>canny_options</code></strong> :&ensp;<code>Optional[<a title="src.distortion.perspective.CannyOptions" href="#src.distortion.perspective.CannyOptions">CannyOptions</a>]</code>, optional</dt>
<dd><code>skimage.feature.canny</code> 옵션</dd>
<dt><strong><code>hough_options</code></strong> :&ensp;<code>Optional[<a title="src.distortion.perspective.HoughOptions" href="#src.distortion.perspective.HoughOptions">HoughOptions</a>]</code>, optional</dt>
<dd><code>skimage.transform.probabilistic_hough_line</code> 옵션</dd>
<dt><strong><code>correction_options</code></strong> :&ensp;<code>Optional[<a title="src.distortion.perspective.CorrectionOptions" href="#src.distortion.perspective.CorrectionOptions">CorrectionOptions</a>]</code>, optional</dt>
<dd>소실점, 시점 보정 행렬의 수치적 추정을 위한 옵션</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PerspectiveCorrection:

  def __init__(self,
               canny_options: Optional[CannyOptions] = None,
               hough_options: Optional[HoughOptions] = None,
               correction_options: Optional[CorrectionOptions] = None) -&gt; None:
    &#34;&#34;&#34;
    영상의 소실점으로부터 시점 왜곡 (perspective distortion)을 보정하는
    Homography 행렬 추정.

    Parameters
    ----------
    canny_options : Optional[CannyOptions], optional
        `skimage.feature.canny` 옵션
    hough_options : Optional[HoughOptions], optional
        `skimage.transform.probabilistic_hough_line` 옵션
    correction_options : Optional[CorrectionOptions], optional
        소실점, 시점 보정 행렬의 수치적 추정을 위한 옵션
    &#34;&#34;&#34;
    if canny_options is None:
      canny_options = CannyOptions()
    if hough_options is None:
      hough_options = HoughOptions()
    if correction_options is None:
      correction_options = CorrectionOptions()

    self._canny_options = canny_options
    self._hough_options = hough_options
    self._opt = correction_options

  @staticmethod
  def preprocess(image: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34;전처리 (회색 변환 및 히스토그램 평활화)&#34;&#34;&#34;
    if image.ndim == 3:
      gray = rgb2gray(image[:, :, :3])
    elif image.ndim == 2:
      gray = image
    else:
      raise ValueError(&#39;Dimension error&#39;)

    preprocessed = equalize_hist(image=gray)

    return preprocessed

  @staticmethod
  def _compute_affine(vp1: np.ndarray, vp2: np.ndarray,
                      H: np.ndarray) -&gt; np.ndarray:
    # Find directions corresponding to vanishing points
    v_post1 = np.dot(H, vp1)
    v_post2 = np.dot(H, vp2)
    v_post1 = v_post1 / np.sqrt(v_post1[0]**2 + v_post1[1]**2)
    v_post2 = v_post2 / np.sqrt(v_post2[0]**2 + v_post2[1]**2)

    directions = np.array([[v_post1[0], -v_post1[0], v_post2[0], -v_post2[0]],
                           [v_post1[1], -v_post1[1], v_post2[1], -v_post2[1]]])

    thetas = np.arctan2(directions[0], directions[1])

    # Find direction closest to horizontal axis
    h_ind = np.argmin(np.abs(thetas))

    # Find positive angle among the rest for the vertical axis
    if h_ind // 2 == 0:
      v_ind = 2 + np.argmax([thetas[2], thetas[3]])
    else:
      v_ind = np.argmax([thetas[2], thetas[3]])

    A1 = np.array([
        [directions[0, v_ind], directions[0, h_ind], 0],
        [directions[1, v_ind], directions[1, h_ind], 0],
        [0, 0, 1],
    ])

    # Might be a reflection. If so, remove reflection.
    if np.linalg.det(A1) &lt; 0:
      A1[:, 0] = -A1[:, 0]

    A = np.linalg.inv(A1)

    return A

  @staticmethod
  def _compute_translate(H: np.ndarray, shape: tuple, clip_factor: float):
    points = [
        [0, 0, shape[1], shape[1]],
        [0, shape[0], 0, shape[0]],
        [1, 1, 1, 1],
    ]
    cords = np.dot(H, points)
    cords = cords[:2] / cords[2]

    tx = min(0.0, cords[0].min())
    ty = min(0.0, cords[1].min())
    max_x = int(cords[0].max() - tx)
    max_y = int(cords[1].max() - ty)

    if clip_factor:
      max_offset = max(shape) * clip_factor / 2.0
      tx = max(tx, -max_offset)
      ty = max(ty, -max_offset)
      max_x = min(max_x, int(-tx + max_offset))
      max_y = min(max_y, int(-ty + max_offset))

    T = np.array([
        [1, 0, -tx],
        [0, 1, -ty],
        [0, 0, 1],
    ])

    return T, max_x, max_y

  def compute_homography(
      self,
      image: np.ndarray,
      vp1: np.ndarray,
      vp2: np.ndarray,
  ) -&gt; CorrectedImage:
    &#34;&#34;&#34;
    두 개의 소실점으로부터 시점 보정을 위한 homography 행렬 추정

    Parameters
    ----------
    image : np.ndarray
        대상 영상
    vp1 : np.ndarray
        소실점 1
    vp2 : np.ndarray
        소실점 2

    Returns
    -------
    CorrectedImage
        보정 결과. (원본/전처리 영상, `edges`, `edgelets` 결과 미포함)
    &#34;&#34;&#34;
    # Find Projective Transform
    vanishing_line = np.cross(vp1, vp2)
    Hproject = np.eye(3)
    Hproject[2] = vanishing_line / vanishing_line[2]
    Hproject = Hproject / Hproject[2, 2]

    # Computes affine transform to make axes corresponding to
    # vanishing points orthogonal
    A = self._compute_affine(vp1=vp1, vp2=vp2, H=Hproject)
    Haffine = np.dot(A, Hproject)

    # Image is translated so that the image is not missed.
    T, max_x, max_y = self._compute_translate(H=Haffine,
                                              shape=image.shape,
                                              clip_factor=self._opt.clip_factor)

    Htranslate = np.dot(T, Haffine)

    corrected = CorrectedImage(vp1=VanishingPoint(vp1),
                               vp2=VanishingPoint(vp2),
                               Hproject=Hproject,
                               Haffine=Haffine,
                               Htranslate=Htranslate,
                               output_shape=(max_y, max_x))

    return corrected

  def _estimate_vanishing_point(
      self,
      edgelets: Edgelets,
      image_shape: tuple,
      target: Optional[int] = None) -&gt; Tuple[VanishingPoint, Edgelets]:
    &#34;&#34;&#34;
    RANSAC을 통해 주어진 edgelet으로부터 vanishing point를 추정하고,
    vanishing point와 vanishing point에 수렴하는 inlier를 제외한 edgelets 반환.

    추정한 vanishing point가 대상 영상 내부에 존재하는 경우,
    해당 inlier를 제외하고 재연산.

    Parameters
    ----------
    edgelets : Edgelets
    image_shape : tuple
    target : Optional[int]
        추정 대상 VP의 위치 (VanishingPoint의 HORIZ, VERT)

    Returns
    -------
    VanishingPoint
        추정한 소실점
    Edgelets
        소실점에 수렴하는 edgelet을 제외한 edgelets

    Raises
    ------
    NotEnoughEdgelets
        조건에 맞지 않는 경우를 제외한 edgelet이 10개 미만인 경우
    ValueError
        Vanishing point 추정 실패
    &#34;&#34;&#34;
    vp = None
    for idx in range(self._opt.vp_iter + 1):
      logger.debug(&#39;Vanishing point iter {}&#39;, idx)
      if edgelets.count &lt; 10:
        raise NotEnoughEdgelets(&#39;Not enough edgelets&#39;)

      vp = ransac_vanishing_point(edgelets=edgelets,
                                  num_ransac_iter=self._opt.ransac_iter,
                                  threshold_inlier=self._opt.threshold)
      edgelets = remove_inliers(vp=vp,
                                edgelets=edgelets,
                                threshold_inlier=(2 * self._opt.threshold))

      vp.compute_position(image_shape=image_shape, margin=self._opt.margin)

      if target is None:
        if self._opt.strict:
          valid_positions = VanishingPoint.STRICT
        else:
          valid_positions = VanishingPoint.SOFT

        if vp.pos in valid_positions:
          break
      else:
        if vp.pos == target:
          break

    else:
      raise ValueError(&#39;Vanishing point 추정 실패&#39;)

    return vp, edgelets

  def _estimate_vanishing_points(
      self,
      edgelets: Edgelets,
      image_shape: Tuple[int, int],
  ) -&gt; Tuple[Optional[VanishingPoint], Optional[VanishingPoint]]:
    &#34;&#34;&#34;
    두 개의 vanishing point 추정

    Parameters
    ----------
    edgelets : Edgelets
        edgelets
    image_shape : Tuple[int, int]
        대상 영상 shape

    Returns
    -------
    Optional[VanishingPoint]
        Vanishing point 1
    Optional[VanishingPoint]
        Vanishing point 2
    &#34;&#34;&#34;
    vp1, vp2 = None, None
    vp1, edgelets2 = self._estimate_vanishing_point(edgelets=edgelets,
                                                    image_shape=image_shape)
    if vp1 is None:
      return None, None

    logger.debug(&#39;VP1: ({:.2f}, {:.2f})&#39;, *vp1.xy)

    target = None
    if self._opt.strict:
      target = (VanishingPoint.VERT
                if vp1.pos == VanishingPoint.HORIZ else VanishingPoint.HORIZ)
    vp2, _ = self._estimate_vanishing_point(edgelets=edgelets2,
                                            image_shape=image_shape,
                                            target=target)

    # 영상 중심으로부터 두 vp의 방향이 유사한지 확인
    if vp2 is not None:
      center = np.array([image_shape[1], image_shape[0]]) / 2.0
      vp1xy = vp1.xy - center
      vp2xy = vp2.xy - center

      delta = np.rad2deg(
          np.arctan2(vp1xy[1], vp1xy[0])  # vp1 angle
          - np.arctan2(vp2xy[1], vp2xy[0])  # vp2 angle
      )

      if np.abs(delta) &lt; 2 * self._opt.threshold:
        logger.warning(&#39;두 vanishing point가 유사함 (각도차: {:.2e} degree)&#39;, delta)
        vp2 = None

    if vp2 is not None:
      logger.debug(&#39;VP2: ({:.2f}, {:.2f})&#39;, *vp2.xy)

    return vp1, vp2

  def perspective_correct(self,
                          image: np.ndarray,
                          mask: Optional[np.ndarray] = None) -&gt; CorrectedImage:
    &#34;&#34;&#34;
    시점 왜곡 보정

    Parameters
    ----------
    image : np.ndarray
        대상 영상

    Returns
    -------
    CorrectedImage
    &#34;&#34;&#34;
    if self._opt.erode and mask is not None:
      logger.debug(&#39;Erode mask (iterations: {})&#39;, self._opt.erode)
      mask = erode(mask.astype(np.uint8),
                   iterations=self._opt.erode).astype(bool)

    preped = self.preprocess(image=image)

    edgelets, edges = compute_edgelets(image=preped,
                                       mask=mask,
                                       canny_options=self._canny_options,
                                       hough_options=self._hough_options)

    vp1, vp2 = self._estimate_vanishing_points(edgelets=edgelets,
                                               image_shape=image.shape[:2])

    if vp1 is not None and vp2 is not None:
      # homography 행렬 추정
      corrected = self.compute_homography(image=image,
                                          vp1=vp1.array,
                                          vp2=vp2.array)
      corrected.image = image
      corrected.preprocessed = preped
      corrected.edges = edges
      corrected.edgelets = edgelets
    else:
      # vp 추정 실패, 중간 과정만 저장
      corrected = CorrectedImage(image=image,
                                 preprocessed=preped,
                                 edges=edges,
                                 edgelets=edgelets,
                                 vp1=vp1,
                                 vp2=vp2)

    return corrected</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="src.distortion.perspective.PerspectiveCorrection.preprocess"><code class="name flex">
<span>def <span class="ident">preprocess</span></span>(<span>image: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>전처리 (회색 변환 및 히스토그램 평활화)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def preprocess(image: np.ndarray) -&gt; np.ndarray:
  &#34;&#34;&#34;전처리 (회색 변환 및 히스토그램 평활화)&#34;&#34;&#34;
  if image.ndim == 3:
    gray = rgb2gray(image[:, :, :3])
  elif image.ndim == 2:
    gray = image
  else:
    raise ValueError(&#39;Dimension error&#39;)

  preprocessed = equalize_hist(image=gray)

  return preprocessed</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.distortion.perspective.PerspectiveCorrection.compute_homography"><code class="name flex">
<span>def <span class="ident">compute_homography</span></span>(<span>self, image: numpy.ndarray, vp1: numpy.ndarray, vp2: numpy.ndarray) ‑> <a title="src.distortion.perspective.CorrectedImage" href="#src.distortion.perspective.CorrectedImage">CorrectedImage</a></span>
</code></dt>
<dd>
<div class="desc"><p>두 개의 소실점으로부터 시점 보정을 위한 homography 행렬 추정</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>대상 영상</dd>
<dt><strong><code>vp1</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>소실점 1</dd>
<dt><strong><code>vp2</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>소실점 2</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="src.distortion.perspective.CorrectedImage" href="#src.distortion.perspective.CorrectedImage">CorrectedImage</a></code></dt>
<dd>보정 결과. (원본/전처리 영상, <code>edges</code>, <code>edgelets</code> 결과 미포함)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_homography(
    self,
    image: np.ndarray,
    vp1: np.ndarray,
    vp2: np.ndarray,
) -&gt; CorrectedImage:
  &#34;&#34;&#34;
  두 개의 소실점으로부터 시점 보정을 위한 homography 행렬 추정

  Parameters
  ----------
  image : np.ndarray
      대상 영상
  vp1 : np.ndarray
      소실점 1
  vp2 : np.ndarray
      소실점 2

  Returns
  -------
  CorrectedImage
      보정 결과. (원본/전처리 영상, `edges`, `edgelets` 결과 미포함)
  &#34;&#34;&#34;
  # Find Projective Transform
  vanishing_line = np.cross(vp1, vp2)
  Hproject = np.eye(3)
  Hproject[2] = vanishing_line / vanishing_line[2]
  Hproject = Hproject / Hproject[2, 2]

  # Computes affine transform to make axes corresponding to
  # vanishing points orthogonal
  A = self._compute_affine(vp1=vp1, vp2=vp2, H=Hproject)
  Haffine = np.dot(A, Hproject)

  # Image is translated so that the image is not missed.
  T, max_x, max_y = self._compute_translate(H=Haffine,
                                            shape=image.shape,
                                            clip_factor=self._opt.clip_factor)

  Htranslate = np.dot(T, Haffine)

  corrected = CorrectedImage(vp1=VanishingPoint(vp1),
                             vp2=VanishingPoint(vp2),
                             Hproject=Hproject,
                             Haffine=Haffine,
                             Htranslate=Htranslate,
                             output_shape=(max_y, max_x))

  return corrected</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.PerspectiveCorrection.perspective_correct"><code class="name flex">
<span>def <span class="ident">perspective_correct</span></span>(<span>self, image: numpy.ndarray, mask: Union[numpy.ndarray, NoneType] = None) ‑> <a title="src.distortion.perspective.CorrectedImage" href="#src.distortion.perspective.CorrectedImage">CorrectedImage</a></span>
</code></dt>
<dd>
<div class="desc"><p>시점 왜곡 보정</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>대상 영상</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="src.distortion.perspective.CorrectedImage" href="#src.distortion.perspective.CorrectedImage">CorrectedImage</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def perspective_correct(self,
                        image: np.ndarray,
                        mask: Optional[np.ndarray] = None) -&gt; CorrectedImage:
  &#34;&#34;&#34;
  시점 왜곡 보정

  Parameters
  ----------
  image : np.ndarray
      대상 영상

  Returns
  -------
  CorrectedImage
  &#34;&#34;&#34;
  if self._opt.erode and mask is not None:
    logger.debug(&#39;Erode mask (iterations: {})&#39;, self._opt.erode)
    mask = erode(mask.astype(np.uint8),
                 iterations=self._opt.erode).astype(bool)

  preped = self.preprocess(image=image)

  edgelets, edges = compute_edgelets(image=preped,
                                     mask=mask,
                                     canny_options=self._canny_options,
                                     hough_options=self._hough_options)

  vp1, vp2 = self._estimate_vanishing_points(edgelets=edgelets,
                                             image_shape=image.shape[:2])

  if vp1 is not None and vp2 is not None:
    # homography 행렬 추정
    corrected = self.compute_homography(image=image,
                                        vp1=vp1.array,
                                        vp2=vp2.array)
    corrected.image = image
    corrected.preprocessed = preped
    corrected.edges = edges
    corrected.edgelets = edgelets
  else:
    # vp 추정 실패, 중간 과정만 저장
    corrected = CorrectedImage(image=image,
                               preprocessed=preped,
                               edges=edges,
                               edgelets=edgelets,
                               vp1=vp1,
                               vp2=vp2)

  return corrected</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="src.distortion.perspective.VanishingPoint"><code class="flex name class">
<span>class <span class="ident">VanishingPoint</span></span>
<span>(</span><span>array: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class VanishingPoint:
  INSIDE = 0
  HORIZ = 1
  VERT = 2
  DIAG = 3

  SOFT = {HORIZ, VERT, DIAG}
  STRICT = {HORIZ, VERT}

  POS_DICT = {
      (True, True): DIAG,
      (True, False): HORIZ,
      (False, True): VERT,
      (False, False): INSIDE
  }

  def __init__(self, array: np.ndarray) -&gt; None:
    if array.shape != (3,):
      raise ValueError(&#39;Invalid vanishing point shape&#39;)

    self._array = array
    self._xy = np.divide(self.array[:2], self._array[2])
    self._pos: Optional[int] = None

  @property
  def array(self) -&gt; np.ndarray:
    return self._array

  @property
  def xy(self) -&gt; np.ndarray:
    return self._xy

  @property
  def pos(self) -&gt; int:
    if self._pos is None:
      raise ValueError(&#39;position not computed&#39;)

    return self._pos

  def compute_position(self, image_shape: tuple, margin=0.1):
    shape = np.array([image_shape[1], image_shape[0]])
    rxy = (self.xy - shape / 2.0) / shape
    hv = np.abs(rxy) &gt; 0.5 + margin

    self._pos = self.POS_DICT[(hv[0], hv[1])]</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="src.distortion.perspective.VanishingPoint.DIAG"><code class="name">var <span class="ident">DIAG</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.HORIZ"><code class="name">var <span class="ident">HORIZ</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.INSIDE"><code class="name">var <span class="ident">INSIDE</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.POS_DICT"><code class="name">var <span class="ident">POS_DICT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.SOFT"><code class="name">var <span class="ident">SOFT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.STRICT"><code class="name">var <span class="ident">STRICT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.VERT"><code class="name">var <span class="ident">VERT</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="src.distortion.perspective.VanishingPoint.array"><code class="name">var <span class="ident">array</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def array(self) -&gt; np.ndarray:
  return self._array</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.pos"><code class="name">var <span class="ident">pos</span> : int</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def pos(self) -&gt; int:
  if self._pos is None:
    raise ValueError(&#39;position not computed&#39;)

  return self._pos</code></pre>
</details>
</dd>
<dt id="src.distortion.perspective.VanishingPoint.xy"><code class="name">var <span class="ident">xy</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def xy(self) -&gt; np.ndarray:
  return self._xy</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="src.distortion.perspective.VanishingPoint.compute_position"><code class="name flex">
<span>def <span class="ident">compute_position</span></span>(<span>self, image_shape: tuple, margin=0.1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_position(self, image_shape: tuple, margin=0.1):
  shape = np.array([image_shape[1], image_shape[0]])
  rxy = (self.xy - shape / 2.0) / shape
  hv = np.abs(rxy) &gt; 0.5 + margin

  self._pos = self.POS_DICT[(hv[0], hv[1])]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.distortion" href="index.html">src.distortion</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.distortion.perspective.compute_edgelets" href="#src.distortion.perspective.compute_edgelets">compute_edgelets</a></code></li>
<li><code><a title="src.distortion.perspective.compute_votes" href="#src.distortion.perspective.compute_votes">compute_votes</a></code></li>
<li><code><a title="src.distortion.perspective.ransac_vanishing_point" href="#src.distortion.perspective.ransac_vanishing_point">ransac_vanishing_point</a></code></li>
<li><code><a title="src.distortion.perspective.remove_inliers" href="#src.distortion.perspective.remove_inliers">remove_inliers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.distortion.perspective.CannyOptions" href="#src.distortion.perspective.CannyOptions">CannyOptions</a></code></h4>
<ul class="">
<li><code><a title="src.distortion.perspective.CannyOptions.high_threshold" href="#src.distortion.perspective.CannyOptions.high_threshold">high_threshold</a></code></li>
<li><code><a title="src.distortion.perspective.CannyOptions.low_threshold" href="#src.distortion.perspective.CannyOptions.low_threshold">low_threshold</a></code></li>
<li><code><a title="src.distortion.perspective.CannyOptions.sigma" href="#src.distortion.perspective.CannyOptions.sigma">sigma</a></code></li>
<li><code><a title="src.distortion.perspective.CannyOptions.use_quantiles" href="#src.distortion.perspective.CannyOptions.use_quantiles">use_quantiles</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.distortion.perspective.CorrectedImage" href="#src.distortion.perspective.CorrectedImage">CorrectedImage</a></code></h4>
<ul class="two-column">
<li><code><a title="src.distortion.perspective.CorrectedImage.Haffine" href="#src.distortion.perspective.CorrectedImage.Haffine">Haffine</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.Hproject" href="#src.distortion.perspective.CorrectedImage.Hproject">Hproject</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.Htranslate" href="#src.distortion.perspective.CorrectedImage.Htranslate">Htranslate</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.correct" href="#src.distortion.perspective.CorrectedImage.correct">correct</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.corrected_image" href="#src.distortion.perspective.CorrectedImage.corrected_image">corrected_image</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.edgelets" href="#src.distortion.perspective.CorrectedImage.edgelets">edgelets</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.edges" href="#src.distortion.perspective.CorrectedImage.edges">edges</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.image" href="#src.distortion.perspective.CorrectedImage.image">image</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.output_shape" href="#src.distortion.perspective.CorrectedImage.output_shape">output_shape</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.preprocessed" href="#src.distortion.perspective.CorrectedImage.preprocessed">preprocessed</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.process_plot" href="#src.distortion.perspective.CorrectedImage.process_plot">process_plot</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.success" href="#src.distortion.perspective.CorrectedImage.success">success</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.vp1" href="#src.distortion.perspective.CorrectedImage.vp1">vp1</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectedImage.vp2" href="#src.distortion.perspective.CorrectedImage.vp2">vp2</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.distortion.perspective.CorrectionOptions" href="#src.distortion.perspective.CorrectionOptions">CorrectionOptions</a></code></h4>
<ul class="two-column">
<li><code><a title="src.distortion.perspective.CorrectionOptions.clip_factor" href="#src.distortion.perspective.CorrectionOptions.clip_factor">clip_factor</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectionOptions.erode" href="#src.distortion.perspective.CorrectionOptions.erode">erode</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectionOptions.margin" href="#src.distortion.perspective.CorrectionOptions.margin">margin</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectionOptions.ransac_iter" href="#src.distortion.perspective.CorrectionOptions.ransac_iter">ransac_iter</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectionOptions.strict" href="#src.distortion.perspective.CorrectionOptions.strict">strict</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectionOptions.threshold" href="#src.distortion.perspective.CorrectionOptions.threshold">threshold</a></code></li>
<li><code><a title="src.distortion.perspective.CorrectionOptions.vp_iter" href="#src.distortion.perspective.CorrectionOptions.vp_iter">vp_iter</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.distortion.perspective.Edgelets" href="#src.distortion.perspective.Edgelets">Edgelets</a></code></h4>
<ul class="">
<li><code><a title="src.distortion.perspective.Edgelets.as_tuple" href="#src.distortion.perspective.Edgelets.as_tuple">as_tuple</a></code></li>
<li><code><a title="src.distortion.perspective.Edgelets.count" href="#src.distortion.perspective.Edgelets.count">count</a></code></li>
<li><code><a title="src.distortion.perspective.Edgelets.directions" href="#src.distortion.perspective.Edgelets.directions">directions</a></code></li>
<li><code><a title="src.distortion.perspective.Edgelets.locations" href="#src.distortion.perspective.Edgelets.locations">locations</a></code></li>
<li><code><a title="src.distortion.perspective.Edgelets.strengths" href="#src.distortion.perspective.Edgelets.strengths">strengths</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.distortion.perspective.HoughOptions" href="#src.distortion.perspective.HoughOptions">HoughOptions</a></code></h4>
<ul class="">
<li><code><a title="src.distortion.perspective.HoughOptions.line_gap" href="#src.distortion.perspective.HoughOptions.line_gap">line_gap</a></code></li>
<li><code><a title="src.distortion.perspective.HoughOptions.line_length" href="#src.distortion.perspective.HoughOptions.line_length">line_length</a></code></li>
<li><code><a title="src.distortion.perspective.HoughOptions.seed" href="#src.distortion.perspective.HoughOptions.seed">seed</a></code></li>
<li><code><a title="src.distortion.perspective.HoughOptions.theta" href="#src.distortion.perspective.HoughOptions.theta">theta</a></code></li>
<li><code><a title="src.distortion.perspective.HoughOptions.threshold" href="#src.distortion.perspective.HoughOptions.threshold">threshold</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.distortion.perspective.NotEnoughEdgelets" href="#src.distortion.perspective.NotEnoughEdgelets">NotEnoughEdgelets</a></code></h4>
</li>
<li>
<h4><code><a title="src.distortion.perspective.PerspectiveCorrection" href="#src.distortion.perspective.PerspectiveCorrection">PerspectiveCorrection</a></code></h4>
<ul class="">
<li><code><a title="src.distortion.perspective.PerspectiveCorrection.compute_homography" href="#src.distortion.perspective.PerspectiveCorrection.compute_homography">compute_homography</a></code></li>
<li><code><a title="src.distortion.perspective.PerspectiveCorrection.perspective_correct" href="#src.distortion.perspective.PerspectiveCorrection.perspective_correct">perspective_correct</a></code></li>
<li><code><a title="src.distortion.perspective.PerspectiveCorrection.preprocess" href="#src.distortion.perspective.PerspectiveCorrection.preprocess">preprocess</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="src.distortion.perspective.VanishingPoint" href="#src.distortion.perspective.VanishingPoint">VanishingPoint</a></code></h4>
<ul class="two-column">
<li><code><a title="src.distortion.perspective.VanishingPoint.DIAG" href="#src.distortion.perspective.VanishingPoint.DIAG">DIAG</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.HORIZ" href="#src.distortion.perspective.VanishingPoint.HORIZ">HORIZ</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.INSIDE" href="#src.distortion.perspective.VanishingPoint.INSIDE">INSIDE</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.POS_DICT" href="#src.distortion.perspective.VanishingPoint.POS_DICT">POS_DICT</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.SOFT" href="#src.distortion.perspective.VanishingPoint.SOFT">SOFT</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.STRICT" href="#src.distortion.perspective.VanishingPoint.STRICT">STRICT</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.VERT" href="#src.distortion.perspective.VanishingPoint.VERT">VERT</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.array" href="#src.distortion.perspective.VanishingPoint.array">array</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.compute_position" href="#src.distortion.perspective.VanishingPoint.compute_position">compute_position</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.pos" href="#src.distortion.perspective.VanishingPoint.pos">pos</a></code></li>
<li><code><a title="src.distortion.perspective.VanishingPoint.xy" href="#src.distortion.perspective.VanishingPoint.xy">xy</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>